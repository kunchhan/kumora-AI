{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Train size: 43410\n",
      "Validation size: 5426\n",
      "Test size: 5427\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "dataset = load_dataset(\"go_emotions\")\n",
    "\n",
    "train_dataset_raw = dataset[\"train\"]\n",
    "val_dataset_raw = dataset[\"validation\"]\n",
    "test_dataset_raw = dataset[\"test\"]\n",
    "\n",
    "print(f\"Train size: {len(train_dataset_raw)}\")\n",
    "print(f\"Validation size: {len(val_dataset_raw)}\")\n",
    "print(f\"Test size: {len(test_dataset_raw)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Pereparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'labels', 'id']\n",
      "{'text': 'Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead', 'labels': [27], 'id': 'ed00q6i'}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset_raw.column_names)\n",
    "print(train_dataset_raw[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of train dataset:\n",
      "{'text': 'Done, good luck with your thing.', 'labels': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'id': 'ef6ysvb'}\n",
      "\n",
      "Head of validation dataset:\n",
      "{'text': 'Is this in New Orleans?? I really feel like this is New Orleans.', 'labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'id': 'edgurhb'}\n",
      "\n",
      "Head of test dataset:\n",
      "{'text': 'I’m really sorry about your situation :( Although I love the names Sapphira, Cirilla, and Scarlett!', 'labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'id': 'eecwqtt'}\n",
      "\n",
      "Number of labels in train dataset: 27\n",
      "All lables in train dataset: [(0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0), (0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1), (0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)]\n",
      "Label counts per class: [4130 2328 1567 2470 2939 1087 1368 2191  641 1269 2022  793  303  853\n",
      "  596 2662   77 1452 2086  164 1581  111 1110  153  545 1326 1060]\n",
      "\n",
      "\n",
      "Empty label samples: 12823\n",
      "Non-empty label samples: 30587\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from collections import Counter\n",
    "\n",
    "num_labels = 27  # GoEmotions has 28 emotion classes (excluding 'neutral')\n",
    "\n",
    "def encode_labels(example):\n",
    "    # Exclude neutral (label 27)\n",
    "    labels = np.zeros(num_labels)\n",
    "    for label in example['labels']:\n",
    "        if label < num_labels:  # Only 0 to 26\n",
    "            labels[label] = 1\n",
    "    example['labels'] = labels.tolist()\n",
    "    return example\n",
    "\n",
    "train_dataset = train_dataset_raw.shuffle(seed=42).map(encode_labels)\n",
    "val_dataset = val_dataset_raw.map(encode_labels)\n",
    "test_dataset = test_dataset_raw.map(encode_labels)\n",
    "\n",
    "\n",
    "print(\"Head of train dataset:\")\n",
    "print(train_dataset[1])\n",
    "print(\"\\nHead of validation dataset:\")\n",
    "print(val_dataset[0])\n",
    "print(\"\\nHead of test dataset:\")\n",
    "print(test_dataset[0])\n",
    "\n",
    "\n",
    "print(\"\\nNumber of labels in train dataset:\", len(train_dataset[0]['labels']))\n",
    "\n",
    "\n",
    "\n",
    "all_labels = [tuple(labels) for labels in train_dataset[\"labels\"]]\n",
    "print(\"All lables in train dataset:\", all_labels[:26])  # Display first 5 for brevity\n",
    "flat_counts = np.sum(train_dataset[\"labels\"], axis=0)\n",
    "print(\"Label counts per class:\", flat_counts)\n",
    "\n",
    "\n",
    "# train_dataset = train_dataset.select(range(5000))\n",
    "# val_dataset = val_dataset.select(range(500))\n",
    "\n",
    "\n",
    "empty_count = 0\n",
    "non_empty_count = 0\n",
    "for sample in train_dataset:\n",
    "    if sum(sample['labels']) == 0:\n",
    "        empty_count += 1\n",
    "    else:\n",
    "        non_empty_count += 1\n",
    "\n",
    "print(f\"\\n\\nEmpty label samples: {empty_count}\")\n",
    "print(f\"Non-empty label samples: {non_empty_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered train size: 30587\n",
      "Filtered validation size: 3834\n"
     ]
    }
   ],
   "source": [
    "# Filter Neutral Samples as empty samples add noise and teach the model that predicting nothing is normal\n",
    "# Filter training samples that have at least one label\n",
    "train_dataset = train_dataset.filter(lambda x: sum(x['labels']) > 0)\n",
    "val_dataset = val_dataset.filter(lambda x: sum(x['labels']) > 0)\n",
    "\n",
    "print(f\"Filtered train size: {len(train_dataset)}\")\n",
    "print(f\"Filtered validation size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average labels/sample: 1.2058717755909374\n",
      "Unique label values: [0 1]\n",
      "\n",
      "\n",
      "Unique label vectors in training set: 642\n",
      "Train sample 0: I would say they do because it was a horrible accident but they were also in the wrong. The military tried to get them to disperse they didnt.\n",
      "Val sample 0:   You know the answer man, you are programmed to capture those codes they send you, don’t avoid them!\n",
      "Train sample 1: Done, good luck with your thing.\n",
      "Val sample 1:   I've never been this sad in my life!\n",
      "Train sample 2: Eat better.\n",
      "Val sample 2:   The economy is heavily controlled and subsidized by the government. In any case, I was poking at the lack of nuance in US politics today\n",
      "Train sample 3: So you stay on your theft from auto waiting for them to dispatch the next shift to the backlog of calls.\n",
      "Val sample 3:   He could have easily taken a real camera from a legitimate source and change the price in Word/Photoshop and then print it out.\n",
      "Train sample 4: Glad to hear it's ubiquitous and not an OS thing.\n",
      "Val sample 4:   Thank you for your vote of confidence, but we statistically can't get to 10 wins.\n"
     ]
    }
   ],
   "source": [
    "label_counts = [sum(example['labels']) for example in train_dataset]\n",
    "print(\"Average labels/sample:\", np.mean(label_counts))\n",
    "print(\"Unique label values:\", np.unique(train_dataset[0]['labels']))\n",
    "\n",
    "\n",
    "labels_array = np.array([x['labels'] for x in train_dataset])\n",
    "print(\"\\n\\nUnique label vectors in training set:\", np.unique(labels_array, axis=0).shape[0])\n",
    "for i in range(5):\n",
    "    print(f\"Train sample {i}: {train_dataset[i]['text']}\")\n",
    "    print(f\"Val sample {i}:   {val_dataset[i]['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Tokenize the Text with DistilBertTokenizer Fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of tokenized train dataset:\n",
      "{'labels': tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0]), 'input_ids': tensor([ 101, 2589, 1010, 2204, 6735, 2007, 2115, 2518, 1012,  102,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_dataset_tk = train_dataset.map(tokenize, batched=True)\n",
    "val_dataset_tk = val_dataset.map(tokenize, batched=True)\n",
    "test_dataset_tk = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# This ensures your dataset is ready for PyTorch training\n",
    "train_dataset_tk.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset_tk.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset_tk.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "print(\"Head of tokenized train dataset:\")\n",
    "print(train_dataset_tk[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "labels_matrix = np.array(train_dataset[\"labels\"])\n",
    "label_freq = labels_matrix.sum(axis=0)\n",
    "num_samples = labels_matrix.shape[0]\n",
    "\n",
    "# Avoid divide-by-zero and clip very large weights\n",
    "pos_weights = (num_samples - label_freq) / (label_freq + 1e-5)\n",
    "pos_weights = np.clip(pos_weights, a_min=1.0, a_max=None)\n",
    "\n",
    "class_weights_tensor = torch.tensor(pos_weights, dtype=torch.float).to(device)\n",
    "\n",
    "\n",
    "class MultiLabelTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = torch.nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor)\n",
    "        loss = loss_fct(logits, labels.float())\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    preds = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "    probs = sigmoid(preds)\n",
    "    optimal_threshold = 0.7  # You can try different values later\n",
    "\n",
    "    y_pred = np.where(probs >= optimal_threshold, 1, 0)\n",
    "\n",
    "    print(\"Sample true:\", labels[0])\n",
    "    print(\"Sample pred:\", y_pred[0])\n",
    "    # print(\"Raw logits sample:\", preds[0])\n",
    "    # print(\"Sigmoid probs sample:\", probs[0])\n",
    "    \n",
    "    f1 = f1_score(labels, y_pred, average='micro')\n",
    "    acc = accuracy_score(labels, y_pred)\n",
    "\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=num_labels,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ").to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lotuso\",\n",
    "    eval_strategy=\"epoch\",   \n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    ")\n",
    "class BestF1Callback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.best_f1 = 0\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        f1 = metrics.get(\"eval_f1\", 0)\n",
    "        if f1 > self.best_f1:\n",
    "            print(f\"\\nNew best F1: {f1:.4f}\")\n",
    "            self.best_f1 = f1\n",
    "            control.should_save = True\n",
    "        else:\n",
    "            control.should_save = False\n",
    "        return control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AdamW\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset_tk, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_tk, batch_size=16)\n",
    "\n",
    "def train_model(train_loader, val_loader, model, training_args):\n",
    "    # Training loop\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}\"):\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
    "            labels = batch[\"labels\"].to(device).float()\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} - Training Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
    "                labels = batch[\"labels\"].cpu().numpy()\n",
    "                logits = model(**inputs).logits\n",
    "                probs = torch.sigmoid(logits).cpu().numpy()\n",
    "                preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(labels)\n",
    "\n",
    "        f1 = f1_score(all_labels, all_preds, average=\"micro\")\n",
    "        print(f\"Epoch {epoch + 1} - Validation F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 1912/1912 [06:31<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 0.1384\n",
      "Epoch 1 - Validation F1: 0.5534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 1912/1912 [08:11<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training Loss: 0.0875\n",
      "Epoch 2 - Validation F1: 0.6043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 1912/1912 [08:16<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training Loss: 0.0744\n",
      "Epoch 3 - Validation F1: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 1912/1912 [08:01<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training Loss: 0.0625\n",
      "Epoch 4 - Validation F1: 0.6089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 1912/1912 [07:58<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training Loss: 0.0509\n",
      "Epoch 5 - Validation F1: 0.5971\n"
     ]
    }
   ],
   "source": [
    "hist = train_model(train_loader, val_loader, model, training_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './saved_final_model/lotus_mul_emotion_classifier_v1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./saved_final_model/lotus_emotion_model_v1/tokenizer_config.json',\n",
       " './saved_final_model/lotus_emotion_model_v1/special_tokens_map.json',\n",
       " './saved_final_model/lotus_emotion_model_v1/vocab.txt',\n",
       " './saved_final_model/lotus_emotion_model_v1/added_tokens.json',\n",
       " './saved_final_model/lotus_emotion_model_v1/tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label_list = [dataset['train'].features['labels'].feature.int2str(i) \n",
    "              for i in range(dataset['train'].features['labels'].feature.num_classes) \n",
    "              if dataset['train'].features['labels'].feature.int2str(i).lower() != 'neutral']\n",
    "\n",
    "# Get label list from the dataset (index to string)\n",
    "id2label = {i: label for i, label in enumerate(label_list)}\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "model.config.id2label = {str(k): v for k, v in id2label.items()}\n",
    "model.config.label2id = label2id\n",
    "model.config.num_labels = len(label_list)\n",
    "model.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "# Save model and tokenizer huggingface format\n",
    "model.save_pretrained(\"./saved_final_model/lotus_emotion_model_v1\")\n",
    "tokenizer.save_pretrained(\"./saved_final_model/lotus_emotion_model_v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('love', 0.9945964217185974)]\n",
      "[('sadness', 0.9196999669075012)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sigmoid function for multi-label output\n",
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Get label index mapping\n",
    "id2label = dataset['train'].features['labels'].feature.int2str\n",
    "\n",
    "\n",
    "def predict_emotions(text, threshold=0.5):\n",
    "    # Tokenize and move input to correct device\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        probs = sigmoid(logits.cpu().numpy()[0])  # move to CPU before numpy\n",
    "\n",
    "    # Return all emotions with prob >= threshold\n",
    "    return [(id2label(i), float(p)) for i, p in enumerate(probs) if p >= threshold]\n",
    "\n",
    "# Example\n",
    "#print(predict_emotions(\"I am scared and angry, but also a bit hopeful.\"))\n",
    "\n",
    "print(predict_emotions(\"loved\"))\n",
    "print(predict_emotions(\"I am happy and sad at the same time.\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
